{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Natural-Language-Processing-Intro\" data-toc-modified-id=\"Natural-Language-Processing-Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Natural Language Processing Intro</a></span></li><li><span><a href=\"#Challenges-of-NLP\" data-toc-modified-id=\"Challenges-of-NLP-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Challenges of NLP</a></span></li><li><span><a href=\"#The-NLP-Pipeline\" data-toc-modified-id=\"The-NLP-Pipeline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The NLP Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Text-processing-involves-removing-the-extra-&quot;junk&quot;\" data-toc-modified-id=\"Text-processing-involves-removing-the-extra-&quot;junk&quot;-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Text processing involves removing the extra \"junk\"</a></span></li><li><span><a href=\"#Feature-Extraction\" data-toc-modified-id=\"Feature-Extraction-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Feature Extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Graph-representation\" data-toc-modified-id=\"Graph-representation-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Graph representation</a></span></li><li><span><a href=\"#Document-level\" data-toc-modified-id=\"Document-level-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Document level</a></span></li><li><span><a href=\"#Words-&amp;-Phrases\" data-toc-modified-id=\"Words-&amp;-Phrases-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Words &amp; Phrases</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Modeling</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very structured language (logic, mathematics, programming, etc) vs a natural language that is fluid, complexity, and unstructured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers bridge the gap by processing words & phrases (identifying parts of speech, keywords, etc.), parsing sentences (statements, questions, etc.), and more advanced techiniques like tone & sentiment analysis and document grouping/clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges of NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to understand meaning for a computer:\n",
    "\n",
    "> I was led to believe that the Fyre Festival would be an amazing, transcendent event - I was conned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambiguity because of lack of **context** (meaning or *semantics*):\n",
    "\n",
    "> The pipe couldn't fit through the hole in the wall since it was too big.\n",
    "\n",
    "versus:\n",
    "\n",
    "> The pipe couldn't fit through the hole in the wall since it was too small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing involves removing the extra \"junk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Can't simply feed in data unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to NLP is to process the **text** (here I mean the text representation of the natural language being used). Then would be extracting features which we can use to model (we'll see soon how to do this given the features later in this module).\n",
    "\n",
    "In this section, we will focus on the text processing portion and some feature extraction/selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet: https://wordnet.princeton.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document level \n",
    "\n",
    "> bag-of-words\n",
    ">\n",
    "> doc2vec\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses:\n",
    "    + Sentiment analysis\n",
    "    + Spam detection\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words & Phrases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> word2vec\n",
    ">\n",
    "> glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses:\n",
    "+ Text generation\n",
    "+ Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using numerical allows the ML algorithms we know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
